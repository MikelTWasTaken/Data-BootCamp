{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Daily Challenge: Data Handling and Analysis in Python\n",
    "\n",
    "\n",
    "# What You Will Learn\n",
    "# Advanced techniques for data normalization, reduction, and aggregation.\n",
    "# Skills in gathering, exploring, integrating, and cleaning data using Python.\n",
    "# Proficiency in using Pandas for complex data manipulation.\n",
    "\n",
    "\n",
    "# Your Task\n",
    "# Download and import the Data Science Job Salary dataset.\n",
    "# Normalize the ‘salary’ column using Min-Max normalization which scales all salary values between 0 and 1.\n",
    "# Implement dimensionality reduction like Principal Component Analysis (PCA) or t-SNE to reduce the number of features (columns) in the dataset.\n",
    "# Group the dataset by the ‘experience_level’ column and calculate the average and median salary for each experience level (e.g., Junior, Mid-level, Senior).\n",
    "\n",
    "# Hint :\n",
    "# As a reminder, normalization is crucial when dealing with data that has different ranges. For example, salary data might have a wide range (e.g., from $20,000 to $200,000). By scaling the data using Min-Max normalization, you make sure that all salary values fall within a consistent range (0 to 1). This is particularly helpful when the data is going to be used in machine learning models, as some algorithms (like k-nearest neighbors or neural networks) perform better when features are normalized. It ensures that no single salary dominates the learning process, making the analysis more balanced.\n",
    "\n",
    "# Dimensionality reduction helps simplify complex datasets by reducing the number of variables under consideration. This can make the data more manageable and help avoid the curse of dimensionality—a phenomenon where machine learning models struggle when dealing with high-dimensional data.\n",
    "# PCA, for instance, helps in retaining the most important information (variance) from the dataset while reducing noise and redundancy.\n",
    "# It can also speed up the training process for models and help in visualizing data in fewer dimensions.\n",
    "\n",
    "# Aggregating data helps in understanding trends within subgroups of the dataset.\n",
    "# Calculating average and median salaries for each experience level gives insights into the compensation distribution and disparities across different job levels. This kind of aggregation can help in answering business questions like “How does salary evolve with experience?” or “What is the salary distribution for senior-level roles?”"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0       job_title   job_type experience_level       location  \\\n",
      "0           0  Data scientist  Full Time           Senior  New York City   \n",
      "1           2  Data scientist  Full Time           Senior         Boston   \n",
      "2           3  Data scientist  Full Time           Senior         London   \n",
      "3           4  Data scientist  Full Time           Senior         Boston   \n",
      "4           5  Data scientist  Full Time           Senior  New York City   \n",
      "\n",
      "  salary_currency  salary  \n",
      "0             USD  149000  \n",
      "1             USD  120000  \n",
      "2             USD   68000  \n",
      "3             USD  120000  \n",
      "4             USD  149000  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "df = pd.read_csv('/Users/teitelbaumsair/Desktop/DI_Bootcamp/W4/D4/DAILY CHALLENGE/datascience_salaries.csv')\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salary Normalized:\n",
      "   salary  salary_normalized\n",
      "0  149000           0.601010\n",
      "1  120000           0.454545\n",
      "2   68000           0.191919\n",
      "3  120000           0.454545\n",
      "4  149000           0.601010\n"
     ]
    }
   ],
   "source": [
    "scaler = MinMaxScaler()\n",
    "\n",
    "if 'salary' in df.columns:\n",
    "    df['salary_normalized'] = scaler.fit_transform(df[['salary']])\n",
    "else:\n",
    "    print(\"Error: 'salary' column not found in the dataset!\")\n",
    "\n",
    "print(\"\\nSalary Normalized:\")\n",
    "print(df[['salary', 'salary_normalized']].head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mplotly\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mexpress\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpx\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m numeric_df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241m.\u001b[39mselect_dtypes(include\u001b[38;5;241m=\u001b[39m[np\u001b[38;5;241m.\u001b[39mnumber])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m numeric_df\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m1\u001b[39m:\n\u001b[1;32m      5\u001b[0m     pca \u001b[38;5;241m=\u001b[39m PCA(n_components\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m2\u001b[39m)  \n",
      "\u001b[0;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "numeric_df = df.select_dtypes(include=[np.number])\n",
    "\n",
    "if numeric_df.shape[1] > 1:\n",
    "    pca = PCA(n_components=2)  \n",
    "    pca_result = pca.fit_transform(numeric_df)\n",
    "    \n",
    "    df['PCA1'] = pca_result[:, 0]\n",
    "    df['PCA2'] = pca_result[:, 1]\n",
    "    \n",
    "    print(\"\\nPCA Results:\")\n",
    "    print(df[['PCA1', 'PCA2']].head())\n",
    "else:\n",
    "    print(\"Error: Not enough numeric features for PCA!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Salary Statistics by Experience Level:\n",
      "  experience_level  average_salary  median_salary\n",
      "0            Entry    36111.111111        30000.0\n",
      "1        Executive    76076.923077        46000.0\n",
      "2              Mid    51786.885246        51000.0\n",
      "3           Senior    75088.033012        68000.0\n"
     ]
    }
   ],
   "source": [
    "if 'experience_level' in df.columns:\n",
    "    salary_stats = df.groupby('experience_level')['salary'].agg(['mean', 'median']).reset_index()\n",
    "    salary_stats.rename(columns={'mean': 'average_salary', 'median': 'median_salary'}, inplace=True)\n",
    "    print(\"\\nSalary Statistics by Experience Level:\")\n",
    "    print(salary_stats)\n",
    "else:\n",
    "    print(\"Error: 'experience_level' column not found in the dataset!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
